# This is a template. Run `cp config.toml.template config.toml` to use it.

LLM_API_KEY="<YOUR OPENAI API KEY>"
WORKSPACE_DIR="./workspace"


[STORAGE]
SQLITE_DB = "db/devika.db"
SCREENSHOTS_DIR = "screenshots"
PDFS_DIR = "pdfs"
PROJECTS_DIR = "projects"
LOGS_DIR = "logs"
REPOS_DIR = "repos"
WEB_SEARCH = "ddgs"

[API_KEYS]
BING = "<YOUR_BING_API_KEY>"
GOOGLE_SEARCH = "<YOUR_GOOGLE_SEARCH_API_KEY>"
GOOGLE_SEARCH_ENGINE_ID = "<YOUR_GOOGLE_SEARCH_ENGINE_ID>"
CLAUDE = "<YOUR_CLAUDE_API_KEY>"
NETLIFY = "<YOUR_NETLIFY_API_KEY>"
OPENAI = "<YOUR_OPENAI_API_KEY>"
GROQ = "<YOUR_GROQ_API_KEY>"
GEMINI = "<YOUR_GEMINI_API_KEY>"

[API_ENDPOINTS]
BING = "https://api.bing.microsoft.com/v7.0/search"
GOOGLE_SEARCH = "https://www.googleapis.com/customsearch/v1"
OLLAMA = "http://127.0.0.1:11434"

[LOGGING]
LOG_REST_API = "true"
LOG_PROMPTS = "false"

#LLM_EMBEDDING_MODEL="llama2" # can be "llama2", "openai", "azureopenai", or "local"

##  Run oobabooga. Make sure to enable these settings in Session: openai + api + listen 
##  Toggle - "Apply flags/extensions and restart"
## Go to the tab "model" - Download model or LoRA download: unit-mesh/autodev-coder

LLM_BASE_URL="http://0.0.0.0:5000"
#LLM_API_KEY="<your-api-key>"
LLM_MODEL="oobabooga/unit-mesh_autodev-coder" #claude-3-opus-20240229
